{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1635a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pickle\n",
    "import random\n",
    "import rlcard\n",
    "import rlcard.envs\n",
    "import yaml\n",
    "\n",
    "from datetime import datetime\n",
    "from rlcard.agents import RandomAgent\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd1fc283",
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.now()\n",
    "formatted = now.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "storage_name = '../Agent-Pro/my_data/DeepSeek R1/' + formatted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3fdea00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DeepSeek R1 model\n",
    "class DEEPSEEKR1:\n",
    "    def __init__(self) -> None:\n",
    "        with open(\"../config.yaml\", \"r\") as file:\n",
    "            config = yaml.safe_load(file)\n",
    "            api_key = config[\"Keys\"][\"DEEPSEEKR1FREE\"]\n",
    "\n",
    "        self.model = config[\"IDs\"][\"DEEPSEEKR1FREE\"]\n",
    "\n",
    "        self.client = OpenAI(\n",
    "            base_url=config[\"Providers\"][\"OPENROUTER\"],\n",
    "            api_key=api_key,\n",
    "        )\n",
    "\n",
    "    def response(self, mes):\n",
    "        response = self.client.chat.completions.create(\n",
    "            model=self.model,\n",
    "            messages=mes)\n",
    "\n",
    "        return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c1c5d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Blackjack Agent\n",
    "class LlmAgent(RandomAgent):\n",
    "    def __init__(self, num_actions):\n",
    "        super().__init__(num_actions)\n",
    "        self.llm = DEEPSEEKR1()\n",
    "\n",
    "        self.behavioral_guideline = \"\"\n",
    "        self.world_modeling = \"\"\n",
    "\n",
    "    def extract_choice(self, text):\n",
    "        text = self.to_lower(text)\n",
    "        last_hit_index = text.rfind(\"hit\")\n",
    "        last_stand_index = text.rfind(\"stand\")\n",
    "        if last_hit_index > last_stand_index:\n",
    "            return \"hit\"\n",
    "        elif last_stand_index > last_hit_index:\n",
    "            return \"stand\"\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    def to_lower(self, str):\n",
    "        lowercase_string = str.lower()\n",
    "        return lowercase_string\n",
    "\n",
    "    def card2string(self, cardList):\n",
    "        str = ''\n",
    "        str = ','.join(cardList)\n",
    "        str = str.replace('C', 'Club ')\n",
    "        str = str.replace('S', 'Spade ')\n",
    "        str = str.replace('H', 'Heart ')\n",
    "        str = str.replace('D', 'Diamond ')\n",
    "        str = str.replace('T', '10')\n",
    "        return str\n",
    "\n",
    "    def step(self, state):\n",
    "        deal_card = state['raw_obs']['dealer hand']\n",
    "        hand_card = state['raw_obs']['player0 hand']\n",
    "        p = []\n",
    "        begin_info = \"I will describe the situation. You have to reason through this in 3-5 steps, then stop. The description begins now. You are an aggressive player of blackjack who likes to take risks to earn high returns. Please beat the dealer and win the game. \"\n",
    "\n",
    "        game_rule = \"Game Rule:\\n1. Please try to get your card total to as close to 31 as possible, without going over, and still having a higher total than the dealer.\\n2. If anyone's point total exceeds 31, he or she loses the game. \\n3. You can only choose one of the following two actions: {\\\"Stand\\\", \\\"Hit\\\"}. If you choose to Stand, you will stop taking cards and wait for the dealer to finish. If you choose to Hit, you can continue to take a card, but there is also the risk of going over 31. \\n4. After all players have completed their hands, the dealer reveals their hidden card. Dealers must hit until their cards total 27 or higher.\\n\"\n",
    "        game_info = \"The dealer's current card is {\" + self.card2string(deal_card) + \"}. The dealer has another hidden card. You don't know what it is. Your current cards are {\" + self.card2string(hand_card) + \"}. \"\n",
    "        \n",
    "        game_info += \"Behavioral guideline: \" + self.behavioral_guideline + \"\\n\"\n",
    "        game_info += \"World modeling: \" + self.world_modeling + \"\\n\"\n",
    "        game_info += \"Please read the behavioral guideline and world modeling carefully. Then you should analyze your own cards and your strategies in Self-belief and then analyze the dealer cards in World-belief. Lastly, please select your action from {\\\"Stand\\\",\\\"Hit\\\"}.### Output Format: Self-Belief is {Belief about youself}. World-Belief is {Belief about the dealer}. My action is {Your action}. Please output in the given format. Do not write anything else.\"\n",
    "\n",
    "        p.append({\"role\": \"user\", \"content\": begin_info + game_rule + game_info})\n",
    "        llm_res = self.llm.response(p)\n",
    "        p.append({\"role\": \"assistant\", \"content\": llm_res})\n",
    "\n",
    "        filename = storage_name + '.yaml'\n",
    "        with open(filename, \"a\") as yaml_file:\n",
    "            yaml.dump(p, yaml_file, default_flow_style=False, allow_unicode=True)\n",
    "        choice = -1\n",
    "        if self.extract_choice(llm_res) == \"hit\":\n",
    "            choice = 0\n",
    "        elif self.extract_choice(llm_res) == \"stand\":\n",
    "            choice = 1\n",
    "        else:\n",
    "            choice = -1\n",
    "            \n",
    "        return choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce1fcc9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DeepSeek agent\n",
    "llm_agent = LlmAgent(num_actions=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca503b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def play(env):\n",
    "    trajectories, payoffs = env.run(is_training=False)\n",
    "    \n",
    "    if len(trajectories[0]) != 0:\n",
    "        final_state = []\n",
    "        action_record = []\n",
    "        state = []\n",
    "        _action_list = []\n",
    "\n",
    "        for i in range(1):\n",
    "            final_state.append(trajectories[i][-1])\n",
    "            state.append(final_state[i]['raw_obs'])\n",
    "\n",
    "        action_record.append(final_state[i]['action_record'])\n",
    "        for i in range(1, len(action_record) + 1):\n",
    "            _action_list.insert(0, action_record[-i])\n",
    "\n",
    "    res_str = ('dealer {}, '.format(state[0]['state'][1]) +\n",
    "                'player {}, '.format(state[0]['state'][0]))\n",
    "    \n",
    "    if payoffs[0] == 1:\n",
    "        final_res = \"win.\"\n",
    "    elif payoffs[0] == 0:\n",
    "        final_res = \"draw.\"\n",
    "    elif payoffs[0] == -1:\n",
    "        final_res = \"lose.\"\n",
    "\n",
    "    p = [{\"final cards\": res_str, \"final results\": final_res}]\n",
    "\n",
    "    filename = storage_name + '.yaml'\n",
    "    with open(filename, \"a\") as yaml_file:\n",
    "        yaml.dump(p, yaml_file, default_flow_style=False, allow_unicode=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4bc77235",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(results, llm, old_policy):\n",
    "    with open(results + '.yaml', 'r') as file:\n",
    "        content = file.read()\n",
    "    log = yaml.safe_load(content)\n",
    "\n",
    "    p = []\n",
    "    \n",
    "    behavioral_guideline = \"\"\n",
    "    world_modeling = \"\"\n",
    "\n",
    "    game_rule = \"Game Rule:\\n1. Please try to get your card total to as close to 31 as possible, without going over, and still having a higher total than the dealer.\\n2. If anyone's point total exceeds 31, he or she loses the game. \\n3. You can only choose one of the following two actions: {\\\"Stand\\\", \\\"Hit\\\"}. If you choose to Stand, you will stop taking cards and wait for the dealer to finish. If you choose to Hit, you can continue to take a card, but there is also the risk of going over 31. \\n4. After all players have completed their hands, the dealer reveals their hidden card. Dealers must hit until their cards total 27 or higher.\\n\"\n",
    "    setup = \"You are a seasoned blackjack expert, and you need to carefully reflect on the following record of this losing game: \"\n",
    "    game_record = f\"Game Record: {content}\\n\"\n",
    "\n",
    "    analysis_setup = \"\"\"\n",
    "    Correctness: Whether its beliefs about yourself, the game, and the dealer align with the final results.\n",
    "    Consistency: Whether each belief and action is self - contradictory.\n",
    "    Reasons: Reflect on why you lost to your dealer, which beliefs and actions are\n",
    "    problematic, and what the underlying reasons are.\n",
    "    ### Output Format: I analyze this game as follows: { Your analysis about the game and belief }.\n",
    "    \"\"\"\n",
    "    \n",
    "    p.append({\"role\": \"user\", \"content\": game_rule + setup + game_record + analysis_setup})\n",
    "    res = llm.response(p)\n",
    "    p.append({\"role\": \"assistant\", \"content\": res})\n",
    "\n",
    "    reflection = \"Policy-Level Reflection: \" + res + \"\\n\"\n",
    "    guidelines = f\"\"\"\n",
    "    Following the previous rigorous analysis, you should distill and articulate a set of\n",
    "    Behavoiral Guidelines and World Modeling. The Behavoiral Guideline is about what\n",
    "    you consider to be a more reasonable and effective behavioral strategy and\n",
    "    suggestions. World Modeling is about the description of the game and the dealer.\n",
    "\n",
    "    Here are some suggestions for you:\n",
    "\n",
    "    Behavoiral Guideline\n",
    "        1-Goal: Please summarize the detailed goal based on your reflection ...\n",
    "        2-Strategy: What kind of strategy can lead you to win in similar games ...\n",
    "        3-Demonstration: Can this game be considered a typical example to be preserved for\n",
    "        future reference ...\n",
    "    World Modeling\n",
    "        1-Rule-Description: Based on the recent reflection , describe any game rules or details\n",
    "        that are easy to overlook ...\n",
    "\n",
    "\n",
    "    Update previous policies that you used to have to better match your current understanding.\n",
    "\n",
    "    Previous Behavoiral Guideline:\n",
    "    {old_policy[0]}\n",
    "\n",
    "    Previous World Modeling:\n",
    "    {old_policy[1]}\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    n = []\n",
    "    n.append({\"role\": \"user\", \"content\": game_record + reflection + guidelines})\n",
    "    res = llm.response(n)\n",
    "    n.append({\"role\": \"assistant\", \"content\": res})\n",
    "\n",
    "    parts = res.split(\"**World Modeling**\")\n",
    "\n",
    "    behavioral_guideline = parts[0].strip()\n",
    "    world_modeling = \"**World Modeling**\" + parts[1].strip()\n",
    "\n",
    "    filename = results + '_train' + '.yaml'\n",
    "    with open(filename, \"a\") as yaml_file:\n",
    "        yaml.dump(p, yaml_file, default_flow_style=False, allow_unicode=True)\n",
    "        yaml.dump(n, yaml_file, default_flow_style=False, allow_unicode=True)\n",
    "\n",
    "    return behavioral_guideline, world_modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2a892e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current game: 0\n"
     ]
    }
   ],
   "source": [
    "# Random games\n",
    "for i in range(0, 1):\n",
    "    now = datetime.now()\n",
    "    formatted = now.strftime(\"%Y-%m-%d %H:%M:%S.%f\")\n",
    "    storage_name = '../Agent-Pro/my_data/test/' + formatted\n",
    "    env = rlcard.make('blackjack', config={'game_num_players': 1, \"seed\": random.randint(0, 10**10)})\n",
    "    env.set_agents([llm_agent])\n",
    "    play(env)\n",
    "\n",
    "    behavioral_guideline, world_modeling = train(storage_name)\n",
    "    llm_agent.behavioral_guideline = behavioral_guideline\n",
    "    llm_agent.world_modeling = world_modeling\n",
    "\n",
    "    print(f\"Current game: {i}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "19a8a4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = DEEPSEEKR1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "84496472",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('**Behavioral Guidelines**  \\n1. **Goal**: Aim to maximize your total as close to 31 as possible without exceeding it, while ensuring your total surpasses the dealer’s (who must reach at least 27). Prioritize aggressive growth in early stages but shift to risk-averse decisions near the upper limit.  \\n2. **Strategy**:  \\n   - **Aggressive Hitting**: Hit when your total is ≤24, as this allows room to grow toward 31 while managing bust risk.  \\n   - **Cautious Standing**: Stand at 25+ if the risk of busting exceeds the potential gain (e.g., at 30, prioritize preserving a strong total).  \\n   - **Dealer Risk Assessment**: Factor in the dealer’s obligation to hit until 27+, which increases their likelihood of busting.  \\n3. **Demonstration**: This game demonstrates the balance between aggression (hitting at 10, 20) and caution (standing at 30). Preserve these scenarios as references for similar high-stakes, risk-reward decisions.',\n",
       " '**World Modeling**1. **Rule-Description**:  \\n   - The dealer’s hidden card combined with visible cards (**Heart 7** here) can create totals requiring multiple hits (e.g., a hidden 10 gives 17 total, forcing the dealer to hit until ≥27). Dealers may draw 2–3 additional cards, significantly raising their bust probability.  \\n   - Winning requires *both* staying under 31 **and** beating the dealer’s total. Even a strong player total (e.g., 30) loses if the dealer reaches 31.  \\n   - Overlooked nuance: Standing at 30 ensures safety but risks losing if the dealer draws 31. Balance near-31 plays with the dealer’s potential outcomes.  \\n\\n**Updated Policies**  \\n- **Previous Guidelines**: Generalized aggression without accounting for dealer’s mandatory hitting.  \\n- **Revised**: Now emphasizes dynamic risk assessment—aggression when totals are low, caution near 31, and leveraging dealer’s higher bust probability.')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train(\"../Agent-Pro/my_data/test/2025-03-25 17:48:06.868309\", llm, [llm_agent.behavioral_guideline, llm_agent.world_modeling])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
