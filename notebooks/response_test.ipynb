{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import json\n",
    "import random\n",
    "import rlcard\n",
    "import rlcard.envs\n",
    "import yaml\n",
    "\n",
    "from datetime import datetime\n",
    "from rlcard.agents import RandomAgent\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "def extract_choice(text):\n",
    "    text = to_lower(text)\n",
    "    last_hit_index = text.rfind(\"hit\")\n",
    "    last_stand_index = text.rfind(\"stand\")\n",
    "    if last_hit_index > last_stand_index:\n",
    "        return \"hit\"\n",
    "    elif last_stand_index > last_hit_index:\n",
    "        return \"stand\"\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def to_lower(str):\n",
    "    lowercase_string = str.lower()\n",
    "    return lowercase_string\n",
    "\n",
    "def card2string(cardList):\n",
    "    str = ''\n",
    "    str = ','.join(cardList)\n",
    "    str = str.replace('C', 'Club ')\n",
    "    str = str.replace('S', 'Spade ')\n",
    "    str = str.replace('H', 'Heart ')\n",
    "    str = str.replace('D', 'Diamond ')\n",
    "    str = str.replace('T', '10')\n",
    "    return str\n",
    "\n",
    "def blackjack_value(hand):\n",
    "    total = 0\n",
    "    ace_count = 0\n",
    "    \n",
    "    for card in hand:\n",
    "        rank = card[1:]  \n",
    "        \n",
    "        if rank == 'A':\n",
    "            total += 11\n",
    "            ace_count += 1\n",
    "        elif rank in {'J', 'Q', 'K', 'T', '10'}:\n",
    "            total += 10\n",
    "        elif rank.isdigit() and 2 <= int(rank) <= 9:\n",
    "            total += int(rank)\n",
    "    \n",
    "    while total > 21 and ace_count > 0:\n",
    "        total -= 10  \n",
    "        ace_count -= 1\n",
    "    \n",
    "    return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DeepSeek R1 model\n",
    "class DEEPSEEKR1:\n",
    "    def __init__(self) -> None:\n",
    "        with open(\"/Users/fitter0happier/Desktop/Coding/NLP/21Mind/config.yaml\", \"r\") as file:\n",
    "            config = yaml.safe_load(file)\n",
    "            api_key = config[\"Keys\"][\"DEEPSEEKR1\"]\n",
    "\n",
    "        self.model = config[\"IDs\"][\"DEEPSEEKR1\"]\n",
    "\n",
    "        self.client = OpenAI(\n",
    "            base_url=config[\"Providers\"][\"OPENROUTER\"],\n",
    "            api_key=api_key,\n",
    "        )\n",
    "\n",
    "    def response(self, mes):\n",
    "        response = self.client.chat.completions.create(\n",
    "            model=self.model,\n",
    "            messages=mes)\n",
    "\n",
    "        return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Blackjack Agent\n",
    "game_style = 'agentpro'\n",
    "now = datetime.now()\n",
    "formatted = now.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "storage_name = '../Agent-Pro/my_data/DeepSeek R1/' + formatted\n",
    "\n",
    "class LlmAgent(RandomAgent):\n",
    "    def __init__(self, num_actions):\n",
    "        super().__init__(num_actions)\n",
    "\n",
    "    @staticmethod\n",
    "    def step(state):\n",
    "        deal_card = state['raw_obs']['dealer hand']\n",
    "        hand_card = state['raw_obs']['player0 hand']\n",
    "        llm = DEEPSEEKR1()\n",
    "        p = []\n",
    "        begin_info = \"You are a player in blackjack. Please beat the dealer and win the game.\\n\"\n",
    "        game_rule = \"Game Rule:\\n1. Please try to get your card total to as close to 21 as possible, without going over, and still having a higher total than the dealer.\\n2. If anyone's point total exceeds 21, he or she loses the game. \\n3. You can only choose one of the following two actions: {\\\"Stand\\\", \\\"Hit\\\"}. If you choose to Stand, you will stop taking cards and wait for the dealer to finish. If you choose to Hit, you can continue to take a card, but there is also the risk of losing the game over 21 points. \\n4. After all players have completed their hands, the dealer reveals their hidden card. Dealers must hit until their cards total 17 or higher.\\n\"\n",
    "        game_info = \"The dealer's current card is {\" + card2string(deal_card) + \"}. The dealer has another hidden card. You don't know what it is. Your current cards are {\" + card2string(hand_card) + \"}. \"\n",
    "\n",
    "        if game_style == 'Vanilla':\n",
    "            p.append({\"role\": \"system\", \"content\": begin_info + game_rule})\n",
    "            game_info += \"Please output your action in following format: ###My action is {your action}, without any other text.\"\n",
    "            p.append({\"role\": \"user\", \"content\": game_info})\n",
    "\n",
    "        if game_style == 'Radical':\n",
    "            begin_info = \"You are an aggressive player of blackjack who likes to take risks to earn high returns. Please beat the dealer and win the game.\"\n",
    "            p.append({\"role\": \"system\", \"content\": begin_info + game_rule})\n",
    "            game_info += \"Please output your action in following format: ###My action is {your action}, without any other text.\"\n",
    "            p.append({\"role\": \"user\", \"content\": game_info})\n",
    "\n",
    "        if game_style == 'ReAct':\n",
    "            p.append({\"role\": \"system\", \"content\": begin_info + game_rule})\n",
    "            game_info += \"Please first think and reason about the current hand and then generate your action as follows: ###My thought is {Your Thought}. My action is {your action}.\"\n",
    "            p.append({\"role\": \"user\", \"content\": game_info})\n",
    "\n",
    "        if game_style == 'ReFlexion':\n",
    "            p.append({\"role\": \"system\", \"content\": begin_info + game_rule})\n",
    "            game_info += \"Please first think and reason about the current hand and then generate your action as follows: ###My thought is {Your Thought}. My action is {your action}.\"\n",
    "            p.append({\"role\": \"user\", \"content\": game_info})\n",
    "            llm_res = llm.response(p)\n",
    "            p.append({\"role\": \"assistant\", \"content\": llm_res})\n",
    "            reflexion_info = \"Please carefully check the response you just output, and then refine your answer . The final output is also in following format: ###My thought is {Your Thought}. My action is {your action}.\"\n",
    "            p.append({\"role\": \"user\", \"content\": reflexion_info})\n",
    "            \n",
    "        if game_style == 'agentpro':\n",
    "            begin_info = \"You are an aggressive player of blackjack who likes to take risks to earn high returns. Please beat the dealer and win the game.\"\n",
    "            p.append({\"role\": \"system\", \"content\": begin_info + game_rule})\n",
    "            game_info += \"Please read the behavoiral guideline and world modeling carefully . Then you should analyze your own cards and your strategies in Self-belief and then analyze the dealer cards in World-belief. Lastly, please select your action from {\\\"Stand\\\",\\\"Hit\\\"}.### Output Format: Self-Belief is {Belief about youself}. World-Belief is {Belief about the dealer}. My action is {Your action}. Please output in the given format.\"\n",
    "            p.append({\"role\": \"user\", \"content\": game_info})\n",
    "        llm_res = llm.response(p)\n",
    "        p.append({\"role\": \"assistant\", \"content\": llm_res})\n",
    "        filename = storage_name + '.yaml'\n",
    "        with open(filename, \"a\") as yaml_file:\n",
    "            yaml.dump(p, yaml_file, default_flow_style=False, allow_unicode=True)\n",
    "        choice = -1\n",
    "        if extract_choice(llm_res) == \"hit\":\n",
    "            choice = 0\n",
    "        elif extract_choice(llm_res) == \"stand\":\n",
    "            choice = 1\n",
    "        else:\n",
    "            choice = -1\n",
    "        return choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment\n",
    "num_players = 1\n",
    "env = rlcard.make(\n",
    "    'blackjack',\n",
    "    config={'game_num_players': num_players, \"seed\": random.randint(0, 10**10)}\n",
    ")\n",
    "\n",
    "llm_agent = LlmAgent(num_actions=env.num_actions)\n",
    "env.set_agents([llm_agent])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_game(env):\n",
    "    trajectories, payoffs = env.run(is_training=False)\n",
    "    print(trajectories)\n",
    "    if len(trajectories[0]) != 0:\n",
    "        final_state = []\n",
    "        action_record = []\n",
    "        state = []\n",
    "        _action_list = []\n",
    "\n",
    "        for i in range(num_players):\n",
    "            final_state.append(trajectories[i][-1])\n",
    "            state.append(final_state[i]['raw_obs'])\n",
    "\n",
    "        action_record.append(final_state[i]['action_record'])\n",
    "        for i in range(1, len(action_record) + 1):\n",
    "            _action_list.insert(0, action_record[-i])\n",
    "\n",
    "    res_str = ('dealer {}, '.format(state[0]['state'][1]) +\n",
    "                'player {}, '.format(state[0]['state'][0]))\n",
    "    if payoffs[0] == 1:\n",
    "        final_res = \"win.\"\n",
    "    elif payoffs[0] == 0:\n",
    "        final_res = \"draw.\"\n",
    "    elif payoffs[0] == -1:\n",
    "        final_res = \"lose.\"\n",
    "    p = [{\"final cards\": res_str, \"final results\": final_res}]\n",
    "    filename = storage_name + '.yaml'\n",
    "    with open(filename, \"a\") as yaml_file:\n",
    "        yaml.dump(p, yaml_file, default_flow_style=False, allow_unicode=True)\n",
    "    return env.get_payoffs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[{'obs': array([12,  9]), 'legal_actions': OrderedDict([(0, None), (1, None)]), 'raw_obs': {'actions': ('hit', 'stand'), 'player0 hand': ['S7', 'C5'], 'dealer hand': ['H9'], 'state': (['S7', 'C5'], ['H9'])}, 'raw_legal_actions': ['hit', 'stand'], 'action_record': [(0, 'hit'), (0, 'stand')]}, 0, {'obs': array([17,  9]), 'legal_actions': OrderedDict([(0, None), (1, None)]), 'raw_obs': {'player0 hand': ['S7', 'C5', 'S5'], 'dealer hand': ['H9'], 'actions': ('hit', 'stand'), 'state': (['S7', 'C5', 'S5'], ['H9'])}, 'raw_legal_actions': ['hit', 'stand'], 'action_record': [(0, 'hit'), (0, 'stand')]}, 1, {'obs': array([17, 18]), 'legal_actions': OrderedDict([(0, None), (1, None)]), 'raw_obs': {'actions': ('hit', 'stand'), 'player0 hand': ['S7', 'C5', 'S5'], 'dealer hand': ['H2', 'H9', 'C7'], 'state': (['S7', 'C5', 'S5'], ['H2', 'H9', 'C7'])}, 'raw_legal_actions': ['hit', 'stand'], 'action_record': [(0, 'hit'), (0, 'stand')]}]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-1])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "now = datetime.now()\n",
    "formatted = now.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "storage_name = '../Agent-Pro/my_data/DeepSeek R1/' + formatted\n",
    "play_game(env)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
