{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: Loading egg at /mnt/appl/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/site-packages/flann-1.9.2-py3.11.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import copy\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import random\n",
    "import rlcard\n",
    "import rlcard.envs\n",
    "import torch\n",
    "import yaml\n",
    "\n",
    "from datetime import datetime\n",
    "from rlcard.agents import RandomAgent\n",
    "from openai import OpenAI\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "def extract_choice(text):\n",
    "    text = to_lower(text)\n",
    "    last_hit_index = text.rfind(\"hit\")\n",
    "    last_stand_index = text.rfind(\"stand\")\n",
    "    if last_hit_index > last_stand_index:\n",
    "        return \"hit\"\n",
    "    elif last_stand_index > last_hit_index:\n",
    "        return \"stand\"\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def to_lower(str):\n",
    "    lowercase_string = str.lower()\n",
    "    return lowercase_string\n",
    "\n",
    "def card2string(cardList):\n",
    "    str = ''\n",
    "    str = ','.join(cardList)\n",
    "    str = str.replace('C', 'Club ')\n",
    "    str = str.replace('S', 'Spade ')\n",
    "    str = str.replace('H', 'Heart ')\n",
    "    str = str.replace('D', 'Diamond ')\n",
    "    str = str.replace('T', '10')\n",
    "    return str\n",
    "\n",
    "def blackjack_value(hand):\n",
    "    total = 0\n",
    "    ace_count = 0\n",
    "    \n",
    "    for card in hand:\n",
    "        rank = card[1:]  \n",
    "        \n",
    "        if rank == 'A':\n",
    "            total += 11\n",
    "            ace_count += 1\n",
    "        elif rank in {'J', 'Q', 'K', 'T', '10'}:\n",
    "            total += 10\n",
    "        elif rank.isdigit() and 2 <= int(rank) <= 9:\n",
    "            total += int(rank)\n",
    "    \n",
    "    while total > 21 and ace_count > 0:\n",
    "        total -= 10  \n",
    "        ace_count -= 1\n",
    "    \n",
    "    return total\n",
    "\n",
    "def color_strategy(val):\n",
    "    \"\"\"Return a CSS background-color depending on the action.\"\"\"\n",
    "    if val == \"S\":\n",
    "        return \"background-color: gold\"      # Stand color\n",
    "    elif val == \"H\":\n",
    "        return \"background-color: white\"     # Hit color\n",
    "    else:\n",
    "        return \"\"  # No styling by default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DeepSeek R1 model\n",
    "class DEEPSEEKR1:\n",
    "    def __init__(self) -> None:\n",
    "        with open(\"../config.yaml\", \"r\") as file:\n",
    "            config = yaml.safe_load(file)\n",
    "            api_key = config[\"Keys\"][\"DEEPSEEKR1PAID\"]\n",
    "\n",
    "        self.model = config[\"IDs\"][\"DEEPSEEKR1PAID\"]\n",
    "\n",
    "        self.client = OpenAI(\n",
    "            base_url=config[\"Providers\"][\"DEEPSEEK\"],\n",
    "            api_key=api_key,\n",
    "        )\n",
    "\n",
    "    def response(self, mes):\n",
    "        response = self.client.chat.completions.create(\n",
    "            model=self.model,\n",
    "            messages=mes)\n",
    "\n",
    "        return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DeepSeek R1 Qwen model\n",
    "class DEEPSEEKR1QWEN:\n",
    "    def __init__(self) -> None:\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\"deepseek-ai/DeepSeek-R1-Distill-Qwen-7B\", trust_remote_code=True)    \n",
    "        self.model = AutoModelForCausalLM.from_pretrained(\"deepseek-ai/DeepSeek-R1-Distill-Qwen-7B\", \n",
    "                                                          device_map=\"auto\", \n",
    "                                                          torch_dtype=\"auto\",\n",
    "                                                          attn_implementation=\"flash_attention_2\",\n",
    "                                                          trust_remote_code=True)\n",
    "\n",
    "        print(self.model.hf_device_map)\n",
    "\n",
    "    def response(self, mes):\n",
    "        input_ids = self.tokenizer.apply_chat_template(\n",
    "            mes,\n",
    "            add_generation_prompt=True,  \n",
    "            return_tensors=\"pt\"\n",
    "        ).to(self.model.device)\n",
    "\n",
    "        attention_mask = input_ids.ne(self.tokenizer.pad_token_id).long()\n",
    "\n",
    "        outputs = self.model.generate(\n",
    "            input_ids,\n",
    "            max_new_tokens=10000,  \n",
    "            temperature=0.6,\n",
    "            top_p = 0.95,\n",
    "            attention_mask=attention_mask,\n",
    "            pad_token_id=self.tokenizer.eos_token_id,\n",
    "            eos_token_id=self.tokenizer.eos_token_id \n",
    "        )\n",
    "\n",
    "        generated_ids = outputs[:, input_ids.shape[1]:]\n",
    "        response = self.tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n",
    "\n",
    "        return response\n",
    "        # return re.split(r'</think>\\s*', response, maxsplit=1)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Blackjack Agent\n",
    "game_style = 'agentpro'\n",
    "now = datetime.now()\n",
    "formatted = now.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "storage_name = '../Agent-Pro/my_data/DeepSeek R1/' + formatted\n",
    "response = ''\n",
    "\n",
    "class LlmAgent(RandomAgent):\n",
    "    def __init__(self, num_actions):\n",
    "        super().__init__(num_actions)\n",
    "        self.llm = DEEPSEEKR1QWEN()\n",
    "\n",
    "    # @staticmethod\n",
    "    def step(self, state):\n",
    "        deal_card = state['raw_obs']['dealer hand']\n",
    "        hand_card = state['raw_obs']['player0 hand']\n",
    "        p = []\n",
    "        begin_info = \"You are a player in blackjack. Please beat the dealer and win the game.\\n\"\n",
    "        game_rule = \"Game Rule:\\n1. Please try to get your card total to as close to 21 as possible, without going over, and still having a higher total than the dealer.\\n2. If anyone's point total exceeds 21, he or she loses the game. \\n3. You can only choose one of the following two actions: {\\\"Stand\\\", \\\"Hit\\\"}. If you choose to Stand, you will stop taking cards and wait for the dealer to finish. If you choose to Hit, you can continue to take a card, but there is also the risk of losing the game over 21 points. \\n4. After all players have completed their hands, the dealer reveals their hidden card. Dealers must hit until their cards total 17 or higher.\\n\"\n",
    "        game_info = \"The dealer's current card is {\" + card2string(deal_card) + \"}. The dealer has another hidden card. You don't know what it is. Your current cards are {\" + card2string(hand_card) + \"}. \"\n",
    "\n",
    "        if game_style == 'Vanilla':\n",
    "            p.append({\"role\": \"system\", \"content\": begin_info + game_rule})\n",
    "            game_info += \"Please output your action in following format: ###My action is {your action}, without any other text.\"\n",
    "            p.append({\"role\": \"user\", \"content\": game_info})\n",
    "\n",
    "        if game_style == 'Radical':\n",
    "            begin_info = \"You are an aggressive player of blackjack who likes to take risks to earn high returns. Please beat the dealer and win the game.\"\n",
    "            p.append({\"role\": \"system\", \"content\": begin_info + game_rule})\n",
    "            game_info += \"Please output your action in following format: ###My action is {your action}, without any other text.\"\n",
    "            p.append({\"role\": \"user\", \"content\": game_info})\n",
    "\n",
    "        if game_style == 'ReAct':\n",
    "            p.append({\"role\": \"system\", \"content\": begin_info + game_rule})\n",
    "            game_info += \"Please first think and reason about the current hand and then generate your action as follows: ###My thought is {Your Thought}. My action is {your action}.\"\n",
    "            p.append({\"role\": \"user\", \"content\": game_info})\n",
    "\n",
    "        if game_style == 'ReFlexion':\n",
    "            p.append({\"role\": \"system\", \"content\": begin_info + game_rule})\n",
    "            game_info += \"Please first think and reason about the current hand and then generate your action as follows: ###My thought is {Your Thought}. My action is {your action}.\"\n",
    "            p.append({\"role\": \"user\", \"content\": game_info})\n",
    "            llm_res = llm.response(p)\n",
    "            p.append({\"role\": \"assistant\", \"content\": llm_res})\n",
    "            reflexion_info = \"Please carefully check the response you just output, and then refine your answer . The final output is also in following format: ###My thought is {Your Thought}. My action is {your action}.\"\n",
    "            p.append({\"role\": \"user\", \"content\": reflexion_info})\n",
    "            \n",
    "        if game_style == 'agentpro':\n",
    "            begin_info = \"I will describe the situation. You have to reason through this in 3-5 steps, then stop. The description begins now. You are an aggressive player of blackjack who likes to take risks to earn high returns. Please beat the dealer and win the game.\"\n",
    "            # p.append({\"role\": \"user\", \"content\": begin_info + game_rule})\n",
    "            game_info += \"Please read the behavoiral guideline and world modeling carefully. Then you should analyze your own cards and your strategies in Self-belief and then analyze the dealer cards in World-belief. Lastly, please select your action from {\\\"Stand\\\",\\\"Hit\\\"}.### Output Format: Self-Belief is {Belief about youself}. World-Belief is {Belief about the dealer}. My action is {Your action}. Please output in the given format. Do not write anything else.\"\n",
    "            # p.append({\"role\": \"user\", \"content\": game_info})\n",
    "            p.append({\"role\": \"user\", \"content\": begin_info + game_rule + game_info})\n",
    "        llm_res = self.llm.response(p)\n",
    "        p.append({\"role\": \"assistant\", \"content\": llm_res})\n",
    "        filename = storage_name + '.yaml'\n",
    "        with open(filename, \"a\") as yaml_file:\n",
    "            yaml.dump(p, yaml_file, default_flow_style=False, allow_unicode=True)\n",
    "        choice = -1\n",
    "        if extract_choice(llm_res) == \"hit\":\n",
    "            choice = 0\n",
    "        elif extract_choice(llm_res) == \"stand\":\n",
    "            choice = 1\n",
    "        else:\n",
    "            choice = -1\n",
    "        return choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results table\n",
    "results = {17: {2: [], 3: [], 4: [], 5: [], 6: [], 7: [], 8: [], 9: [], 10: [], 'A': []},\n",
    "           16: {2: [], 3: [], 4: [], 5: [], 6: [], 7: [], 8: [], 9: [], 10: [], 'A': []},\n",
    "           15: {2: [], 3: [], 4: [], 5: [], 6: [], 7: [], 8: [], 9: [], 10: [], 'A': []},\n",
    "           14: {2: [], 3: [], 4: [], 5: [], 6: [], 7: [], 8: [], 9: [], 10: [], 'A': []},\n",
    "           13: {2: [], 3: [], 4: [], 5: [], 6: [], 7: [], 8: [], 9: [], 10: [], 'A': []},\n",
    "           12: {2: [], 3: [], 4: [], 5: [], 6: [], 7: [], 8: [], 9: [], 10: [], 'A': []},\n",
    "           11: {2: [], 3: [], 4: [], 5: [], 6: [], 7: [], 8: [], 9: [], 10: [], 'A': []},\n",
    "           10: {2: [], 3: [], 4: [], 5: [], 6: [], 7: [], 8: [], 9: [], 10: [], 'A': []},\n",
    "            9: {2: [], 3: [], 4: [], 5: [], 6: [], 7: [], 8: [], 9: [], 10: [], 'A': []},\n",
    "            8: {2: [], 3: [], 4: [], 5: [], 6: [], 7: [], 8: [], 9: [], 10: [], 'A': []}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to store found seeds\n",
    "found_seeds = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random agent to make env run\n",
    "agent = RandomAgent(num_actions=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Searching for seeds to launch evaluation\n",
    "for i in range(100000):\n",
    "    env = rlcard.make(\"blackjack\", config={\"seed\": i})\n",
    "    env.set_agents([agent])\n",
    "    trajectories, payoffs = env.run(is_training=False)\n",
    "\n",
    "    for j, situation in enumerate(trajectories[0][:1]):\n",
    "        last_hand_value = int(trajectories[0][j]['obs'][0])\n",
    "        if last_hand_value <= 17 and last_hand_value >= 8:\n",
    "            dealer_value = int(trajectories[0][j]['obs'][1]) \n",
    "            if (last_hand_value, dealer_value) not in found_seeds.keys():\n",
    "                found_seeds[(last_hand_value, dealer_value)] = [i]\n",
    "            elif len(found_seeds[(last_hand_value, dealer_value)]) < 10:\n",
    "                found_seeds[(last_hand_value, dealer_value)].append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c1f08e438334757a5a82049a7f0dd22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/3.07k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4598fa149754416ca064cc0b721b24f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/7.03M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2945248ed3794093a8afe760fce2b2e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/664 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbf7db46809b482eaa5ef5d4996be6a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/64.0k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40dfc70fd2d44eb8a734d34c44429986",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2ff1b18dd414f32a7b0e9cec1caaf77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-000008.safetensors:   0%|          | 0.00/8.79G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61604c6e67e44583b2404f59700dc2d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-000008.safetensors:   0%|          | 0.00/8.78G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9a122777f624cd59ebfa122cd7ae65a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-000008.safetensors:   0%|          | 0.00/8.78G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c45b777531f4cbd8c6b4fc3f2b0a581",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00004-of-000008.safetensors:   0%|          | 0.00/8.78G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b8a3464817f4f2f983d64cdc695dc70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00005-of-000008.safetensors:   0%|          | 0.00/8.78G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ce83b61e1c04b1e85ce1f2855a7c80a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00006-of-000008.safetensors:   0%|          | 0.00/8.78G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81ee198100404419a9d456a80235e48c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00007-of-000008.safetensors:   0%|          | 0.00/8.78G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f348421baa9c4944b6b559e79a1db763",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00008-of-000008.safetensors:   0%|          | 0.00/4.07G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f617cf4ce6644401bd5e996f1ed71c0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e59e345fd9f4bd0954183e7120b441f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/181 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model.embed_tokens': 0, 'model.layers.0': 0, 'model.layers.1': 0, 'model.layers.2': 0, 'model.layers.3': 0, 'model.layers.4': 0, 'model.layers.5': 0, 'model.layers.6': 1, 'model.layers.7': 1, 'model.layers.8': 1, 'model.layers.9': 1, 'model.layers.10': 1, 'model.layers.11': 1, 'model.layers.12': 1, 'model.layers.13': 1, 'model.layers.14': 1, 'model.layers.15': 2, 'model.layers.16': 2, 'model.layers.17': 2, 'model.layers.18': 2, 'model.layers.19': 2, 'model.layers.20': 2, 'model.layers.21': 2, 'model.layers.22': 2, 'model.layers.23': 2, 'model.layers.24': 3, 'model.layers.25': 3, 'model.layers.26': 3, 'model.layers.27': 3, 'model.layers.28': 3, 'model.layers.29': 3, 'model.layers.30': 3, 'model.layers.31': 3, 'model.layers.32': 3, 'model.layers.33': 4, 'model.layers.34': 4, 'model.layers.35': 4, 'model.layers.36': 4, 'model.layers.37': 4, 'model.layers.38': 4, 'model.layers.39': 4, 'model.layers.40': 4, 'model.layers.41': 4, 'model.layers.42': 5, 'model.layers.43': 5, 'model.layers.44': 5, 'model.layers.45': 5, 'model.layers.46': 5, 'model.layers.47': 5, 'model.layers.48': 5, 'model.layers.49': 5, 'model.layers.50': 5, 'model.layers.51': 6, 'model.layers.52': 6, 'model.layers.53': 6, 'model.layers.54': 6, 'model.layers.55': 6, 'model.layers.56': 6, 'model.layers.57': 6, 'model.layers.58': 6, 'model.layers.59': 6, 'model.layers.60': 7, 'model.layers.61': 7, 'model.layers.62': 7, 'model.layers.63': 7, 'model.norm': 7, 'model.rotary_emb': 7, 'lm_head': 7}\n"
     ]
    }
   ],
   "source": [
    "# DeepSeek agent\n",
    "llm_agent = LlmAgent(num_actions=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_game(env):\n",
    "    trajectories, payoffs = env.run(is_training=False)\n",
    "    if len(trajectories[0]) != 0:\n",
    "        final_state = []\n",
    "        action_record = []\n",
    "        state = []\n",
    "        _action_list = []\n",
    "\n",
    "        for i in range(1):\n",
    "            final_state.append(trajectories[i][-1])\n",
    "            state.append(final_state[i]['raw_obs'])\n",
    "\n",
    "        action_record.append(final_state[i]['action_record'])\n",
    "        for i in range(1, len(action_record) + 1):\n",
    "            _action_list.insert(0, action_record[-i])\n",
    "\n",
    "    last_hand_value = 0\n",
    "    for i, situation in enumerate(trajectories[0][:-1]):\n",
    "        if (i % 2 == 0): # State\n",
    "            last_hand_value = int(trajectories[0][i]['obs'][0])\n",
    "            dealer_value = int(trajectories[0][i]['obs'][1]) \n",
    "            dealer_value = dealer_value if dealer_value <= 10 else 'A'\n",
    "        else: # Action\n",
    "            action = int(situation)\n",
    "            if last_hand_value >= 8 and last_hand_value <= 17:\n",
    "                results[last_hand_value][dealer_value].append(action)\n",
    "\n",
    "    res_str = ('dealer {}, '.format(state[0]['state'][1]) +\n",
    "                'player {}, '.format(state[0]['state'][0]))\n",
    "    if payoffs[0] == 1:\n",
    "        final_res = \"win.\"\n",
    "    elif payoffs[0] == 0:\n",
    "        final_res = \"draw.\"\n",
    "    elif payoffs[0] == -1:\n",
    "        final_res = \"lose.\"\n",
    "    p = [{\"final cards\": res_str, \"final results\": final_res}]\n",
    "    filename = storage_name + '.yaml'\n",
    "    with open(filename, \"a\") as yaml_file:\n",
    "        yaml.dump(p, yaml_file, default_flow_style=False, allow_unicode=True)\n",
    "    return env.get_payoffs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current game: 1\n",
      "Current game: 2\n",
      "Current game: 3\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 13\u001b[0m\n\u001b[1;32m      6\u001b[0m env \u001b[38;5;241m=\u001b[39m rlcard\u001b[38;5;241m.\u001b[39mmake(\n\u001b[1;32m      7\u001b[0m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mblackjack\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      8\u001b[0m config\u001b[38;5;241m=\u001b[39m{\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgame_num_players\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseed\u001b[39m\u001b[38;5;124m\"\u001b[39m: random\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m10\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m10\u001b[39m)\n\u001b[1;32m     11\u001b[0m })\n\u001b[1;32m     12\u001b[0m env\u001b[38;5;241m.\u001b[39mset_agents([llm_agent])\n\u001b[0;32m---> 13\u001b[0m \u001b[43mplay_game\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCurrent game: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "Cell \u001b[0;32mIn[8], line 2\u001b[0m, in \u001b[0;36mplay_game\u001b[0;34m(env)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplay_game\u001b[39m(env):\n\u001b[0;32m----> 2\u001b[0m     trajectories, payoffs \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mis_training\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(trajectories[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m      4\u001b[0m         final_state \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/rlcard/envs/env.py:144\u001b[0m, in \u001b[0;36mEnv.run\u001b[0;34m(self, is_training)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_over():\n\u001b[1;32m    142\u001b[0m     \u001b[38;5;66;03m# Agent plays\u001b[39;00m\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_training:\n\u001b[0;32m--> 144\u001b[0m         action, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43magents\u001b[49m\u001b[43m[\u001b[49m\u001b[43mplayer_id\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    146\u001b[0m         action \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magents[player_id]\u001b[38;5;241m.\u001b[39mstep(state)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/rlcard/agents/random_agent.py:47\u001b[0m, in \u001b[0;36mRandomAgent.eval_step\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m     44\u001b[0m info \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m     45\u001b[0m info[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprobs\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m {state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraw_legal_actions\u001b[39m\u001b[38;5;124m'\u001b[39m][i]: probs[\u001b[38;5;28mlist\u001b[39m(state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlegal_actions\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mkeys())[i]] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlegal_actions\u001b[39m\u001b[38;5;124m'\u001b[39m]))}\n\u001b[0;32m---> 47\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m, info\n",
      "Cell \u001b[0;32mIn[4], line 53\u001b[0m, in \u001b[0;36mLlmAgent.step\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;66;03m# p.append({\"role\": \"user\", \"content\": game_info})\u001b[39;00m\n\u001b[1;32m     52\u001b[0m     p\u001b[38;5;241m.\u001b[39mappend({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: begin_info \u001b[38;5;241m+\u001b[39m game_rule \u001b[38;5;241m+\u001b[39m game_info})\n\u001b[0;32m---> 53\u001b[0m llm_res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mllm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m p\u001b[38;5;241m.\u001b[39mappend({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124massistant\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: llm_res})\n\u001b[1;32m     55\u001b[0m filename \u001b[38;5;241m=\u001b[39m storage_name \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.yaml\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "Cell \u001b[0;32mIn[3], line 22\u001b[0m, in \u001b[0;36mDEEPSEEKR1QWEN.response\u001b[0;34m(self, mes)\u001b[0m\n\u001b[1;32m     14\u001b[0m input_ids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer\u001b[38;5;241m.\u001b[39mapply_chat_template(\n\u001b[1;32m     15\u001b[0m     mes,\n\u001b[1;32m     16\u001b[0m     add_generation_prompt\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,  \n\u001b[1;32m     17\u001b[0m     return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     18\u001b[0m )\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m     20\u001b[0m attention_mask \u001b[38;5;241m=\u001b[39m input_ids\u001b[38;5;241m.\u001b[39mne(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer\u001b[38;5;241m.\u001b[39mpad_token_id)\u001b[38;5;241m.\u001b[39mlong()\n\u001b[0;32m---> 22\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.6\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.95\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpad_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meos_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[43meos_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meos_token_id\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m generated_ids \u001b[38;5;241m=\u001b[39m outputs[:, input_ids\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]:]\n\u001b[1;32m     33\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer\u001b[38;5;241m.\u001b[39mdecode(generated_ids[\u001b[38;5;241m0\u001b[39m], skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/mnt/appl/software/PyTorch/2.3.0-foss-2023b-CUDA-12.4.0/lib/python3.11/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/transformers/generation/utils.py:2223\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   2215\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   2216\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   2217\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_return_sequences,\n\u001b[1;32m   2218\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   2219\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   2220\u001b[0m     )\n\u001b[1;32m   2222\u001b[0m     \u001b[38;5;66;03m# 12. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[39;00m\n\u001b[0;32m-> 2223\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2224\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2225\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2226\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2227\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2228\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2229\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2230\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2231\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2233\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;129;01min\u001b[39;00m (GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SAMPLE, GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SEARCH):\n\u001b[1;32m   2234\u001b[0m     \u001b[38;5;66;03m# 11. prepare beam search scorer\u001b[39;00m\n\u001b[1;32m   2235\u001b[0m     beam_scorer \u001b[38;5;241m=\u001b[39m BeamSearchScorer(\n\u001b[1;32m   2236\u001b[0m         batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   2237\u001b[0m         num_beams\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_beams,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2242\u001b[0m         max_length\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mmax_length,\n\u001b[1;32m   2243\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/transformers/generation/utils.py:3257\u001b[0m, in \u001b[0;36mGenerationMixin._sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   3255\u001b[0m     probs \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39msoftmax(next_token_scores, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m   3256\u001b[0m     \u001b[38;5;66;03m# TODO (joao): this OP throws \"skipping cudagraphs due to ['incompatible ops']\", find solution\u001b[39;00m\n\u001b[0;32m-> 3257\u001b[0m     next_tokens \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmultinomial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m   3258\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3259\u001b[0m     next_tokens \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39margmax(next_token_scores, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Random games\n",
    "for i in range(1, 1001):\n",
    "    now = datetime.now()\n",
    "    formatted = now.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    storage_name = '../Agent-Pro/my_data/WSB/' + formatted\n",
    "    env = rlcard.make(\n",
    "    'blackjack',\n",
    "    config={\n",
    "        'game_num_players': 1,\n",
    "        \"seed\": random.randint(0, 10**10)\n",
    "    })\n",
    "    env.set_agents([llm_agent])\n",
    "    play_game(env)\n",
    "    print(f\"Current game: {i}\")\n",
    "    if i % 100 == 0:\n",
    "        with open(f\"../dicts/data_{formatted}.pkl\", \"wb\") as f:\n",
    "            pickle.dump(data, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert lists into letters\n",
    "results_copy = copy.deepcopy(results)\n",
    "for row in results.items():\n",
    "    for key in row[1].keys():\n",
    "        row[1][key] = 'H' if round(sum(row[1][key]) / len(row[1][key])) == 0 else 'S'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_ee703_row0_col0, #T_ee703_row0_col6, #T_ee703_row0_col7, #T_ee703_row0_col8, #T_ee703_row0_col9, #T_ee703_row1_col0, #T_ee703_row1_col2, #T_ee703_row1_col4, #T_ee703_row1_col5, #T_ee703_row1_col6, #T_ee703_row1_col7, #T_ee703_row1_col8, #T_ee703_row1_col9, #T_ee703_row2_col0, #T_ee703_row2_col1, #T_ee703_row2_col2, #T_ee703_row2_col3, #T_ee703_row2_col4, #T_ee703_row2_col5, #T_ee703_row2_col6, #T_ee703_row2_col7, #T_ee703_row2_col8, #T_ee703_row2_col9, #T_ee703_row3_col0, #T_ee703_row3_col1, #T_ee703_row3_col2, #T_ee703_row3_col3, #T_ee703_row3_col4, #T_ee703_row3_col5, #T_ee703_row3_col6, #T_ee703_row3_col7, #T_ee703_row3_col8, #T_ee703_row3_col9, #T_ee703_row4_col0, #T_ee703_row4_col1, #T_ee703_row4_col2, #T_ee703_row4_col3, #T_ee703_row4_col4, #T_ee703_row4_col5, #T_ee703_row4_col6, #T_ee703_row4_col7, #T_ee703_row4_col8, #T_ee703_row4_col9, #T_ee703_row5_col0, #T_ee703_row5_col1, #T_ee703_row5_col2, #T_ee703_row5_col3, #T_ee703_row5_col4, #T_ee703_row5_col5, #T_ee703_row5_col6, #T_ee703_row5_col7, #T_ee703_row5_col8, #T_ee703_row5_col9, #T_ee703_row6_col0, #T_ee703_row6_col1, #T_ee703_row6_col2, #T_ee703_row6_col3, #T_ee703_row6_col4, #T_ee703_row6_col5, #T_ee703_row6_col6, #T_ee703_row6_col7, #T_ee703_row6_col8, #T_ee703_row6_col9, #T_ee703_row7_col0, #T_ee703_row7_col1, #T_ee703_row7_col2, #T_ee703_row7_col3, #T_ee703_row7_col4, #T_ee703_row7_col5, #T_ee703_row7_col6, #T_ee703_row7_col7, #T_ee703_row7_col8, #T_ee703_row7_col9, #T_ee703_row8_col0, #T_ee703_row8_col1, #T_ee703_row8_col2, #T_ee703_row8_col3, #T_ee703_row8_col4, #T_ee703_row8_col5, #T_ee703_row8_col6, #T_ee703_row8_col7, #T_ee703_row8_col8, #T_ee703_row8_col9, #T_ee703_row9_col0, #T_ee703_row9_col1, #T_ee703_row9_col2, #T_ee703_row9_col3, #T_ee703_row9_col4, #T_ee703_row9_col5, #T_ee703_row9_col6, #T_ee703_row9_col7, #T_ee703_row9_col8, #T_ee703_row9_col9 {\n",
       "  background-color: white;\n",
       "}\n",
       "#T_ee703_row0_col1, #T_ee703_row0_col2, #T_ee703_row0_col3, #T_ee703_row0_col4, #T_ee703_row0_col5, #T_ee703_row1_col1, #T_ee703_row1_col3 {\n",
       "  background-color: gold;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_ee703\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_ee703_level0_col0\" class=\"col_heading level0 col0\" >2</th>\n",
       "      <th id=\"T_ee703_level0_col1\" class=\"col_heading level0 col1\" >3</th>\n",
       "      <th id=\"T_ee703_level0_col2\" class=\"col_heading level0 col2\" >4</th>\n",
       "      <th id=\"T_ee703_level0_col3\" class=\"col_heading level0 col3\" >5</th>\n",
       "      <th id=\"T_ee703_level0_col4\" class=\"col_heading level0 col4\" >6</th>\n",
       "      <th id=\"T_ee703_level0_col5\" class=\"col_heading level0 col5\" >7</th>\n",
       "      <th id=\"T_ee703_level0_col6\" class=\"col_heading level0 col6\" >8</th>\n",
       "      <th id=\"T_ee703_level0_col7\" class=\"col_heading level0 col7\" >9</th>\n",
       "      <th id=\"T_ee703_level0_col8\" class=\"col_heading level0 col8\" >10</th>\n",
       "      <th id=\"T_ee703_level0_col9\" class=\"col_heading level0 col9\" >A</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_ee703_level0_row0\" class=\"row_heading level0 row0\" >17</th>\n",
       "      <td id=\"T_ee703_row0_col0\" class=\"data row0 col0\" >H</td>\n",
       "      <td id=\"T_ee703_row0_col1\" class=\"data row0 col1\" >S</td>\n",
       "      <td id=\"T_ee703_row0_col2\" class=\"data row0 col2\" >S</td>\n",
       "      <td id=\"T_ee703_row0_col3\" class=\"data row0 col3\" >S</td>\n",
       "      <td id=\"T_ee703_row0_col4\" class=\"data row0 col4\" >S</td>\n",
       "      <td id=\"T_ee703_row0_col5\" class=\"data row0 col5\" >S</td>\n",
       "      <td id=\"T_ee703_row0_col6\" class=\"data row0 col6\" >H</td>\n",
       "      <td id=\"T_ee703_row0_col7\" class=\"data row0 col7\" >H</td>\n",
       "      <td id=\"T_ee703_row0_col8\" class=\"data row0 col8\" >H</td>\n",
       "      <td id=\"T_ee703_row0_col9\" class=\"data row0 col9\" >H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ee703_level0_row1\" class=\"row_heading level0 row1\" >16</th>\n",
       "      <td id=\"T_ee703_row1_col0\" class=\"data row1 col0\" >H</td>\n",
       "      <td id=\"T_ee703_row1_col1\" class=\"data row1 col1\" >S</td>\n",
       "      <td id=\"T_ee703_row1_col2\" class=\"data row1 col2\" >H</td>\n",
       "      <td id=\"T_ee703_row1_col3\" class=\"data row1 col3\" >S</td>\n",
       "      <td id=\"T_ee703_row1_col4\" class=\"data row1 col4\" >H</td>\n",
       "      <td id=\"T_ee703_row1_col5\" class=\"data row1 col5\" >H</td>\n",
       "      <td id=\"T_ee703_row1_col6\" class=\"data row1 col6\" >H</td>\n",
       "      <td id=\"T_ee703_row1_col7\" class=\"data row1 col7\" >H</td>\n",
       "      <td id=\"T_ee703_row1_col8\" class=\"data row1 col8\" >H</td>\n",
       "      <td id=\"T_ee703_row1_col9\" class=\"data row1 col9\" >H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ee703_level0_row2\" class=\"row_heading level0 row2\" >15</th>\n",
       "      <td id=\"T_ee703_row2_col0\" class=\"data row2 col0\" >H</td>\n",
       "      <td id=\"T_ee703_row2_col1\" class=\"data row2 col1\" >H</td>\n",
       "      <td id=\"T_ee703_row2_col2\" class=\"data row2 col2\" >H</td>\n",
       "      <td id=\"T_ee703_row2_col3\" class=\"data row2 col3\" >H</td>\n",
       "      <td id=\"T_ee703_row2_col4\" class=\"data row2 col4\" >H</td>\n",
       "      <td id=\"T_ee703_row2_col5\" class=\"data row2 col5\" >H</td>\n",
       "      <td id=\"T_ee703_row2_col6\" class=\"data row2 col6\" >H</td>\n",
       "      <td id=\"T_ee703_row2_col7\" class=\"data row2 col7\" >H</td>\n",
       "      <td id=\"T_ee703_row2_col8\" class=\"data row2 col8\" >H</td>\n",
       "      <td id=\"T_ee703_row2_col9\" class=\"data row2 col9\" >H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ee703_level0_row3\" class=\"row_heading level0 row3\" >14</th>\n",
       "      <td id=\"T_ee703_row3_col0\" class=\"data row3 col0\" >H</td>\n",
       "      <td id=\"T_ee703_row3_col1\" class=\"data row3 col1\" >H</td>\n",
       "      <td id=\"T_ee703_row3_col2\" class=\"data row3 col2\" >H</td>\n",
       "      <td id=\"T_ee703_row3_col3\" class=\"data row3 col3\" >H</td>\n",
       "      <td id=\"T_ee703_row3_col4\" class=\"data row3 col4\" >H</td>\n",
       "      <td id=\"T_ee703_row3_col5\" class=\"data row3 col5\" >H</td>\n",
       "      <td id=\"T_ee703_row3_col6\" class=\"data row3 col6\" >H</td>\n",
       "      <td id=\"T_ee703_row3_col7\" class=\"data row3 col7\" >H</td>\n",
       "      <td id=\"T_ee703_row3_col8\" class=\"data row3 col8\" >H</td>\n",
       "      <td id=\"T_ee703_row3_col9\" class=\"data row3 col9\" >H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ee703_level0_row4\" class=\"row_heading level0 row4\" >13</th>\n",
       "      <td id=\"T_ee703_row4_col0\" class=\"data row4 col0\" >H</td>\n",
       "      <td id=\"T_ee703_row4_col1\" class=\"data row4 col1\" >H</td>\n",
       "      <td id=\"T_ee703_row4_col2\" class=\"data row4 col2\" >H</td>\n",
       "      <td id=\"T_ee703_row4_col3\" class=\"data row4 col3\" >H</td>\n",
       "      <td id=\"T_ee703_row4_col4\" class=\"data row4 col4\" >H</td>\n",
       "      <td id=\"T_ee703_row4_col5\" class=\"data row4 col5\" >H</td>\n",
       "      <td id=\"T_ee703_row4_col6\" class=\"data row4 col6\" >H</td>\n",
       "      <td id=\"T_ee703_row4_col7\" class=\"data row4 col7\" >H</td>\n",
       "      <td id=\"T_ee703_row4_col8\" class=\"data row4 col8\" >H</td>\n",
       "      <td id=\"T_ee703_row4_col9\" class=\"data row4 col9\" >H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ee703_level0_row5\" class=\"row_heading level0 row5\" >12</th>\n",
       "      <td id=\"T_ee703_row5_col0\" class=\"data row5 col0\" >H</td>\n",
       "      <td id=\"T_ee703_row5_col1\" class=\"data row5 col1\" >H</td>\n",
       "      <td id=\"T_ee703_row5_col2\" class=\"data row5 col2\" >H</td>\n",
       "      <td id=\"T_ee703_row5_col3\" class=\"data row5 col3\" >H</td>\n",
       "      <td id=\"T_ee703_row5_col4\" class=\"data row5 col4\" >H</td>\n",
       "      <td id=\"T_ee703_row5_col5\" class=\"data row5 col5\" >H</td>\n",
       "      <td id=\"T_ee703_row5_col6\" class=\"data row5 col6\" >H</td>\n",
       "      <td id=\"T_ee703_row5_col7\" class=\"data row5 col7\" >H</td>\n",
       "      <td id=\"T_ee703_row5_col8\" class=\"data row5 col8\" >H</td>\n",
       "      <td id=\"T_ee703_row5_col9\" class=\"data row5 col9\" >H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ee703_level0_row6\" class=\"row_heading level0 row6\" >11</th>\n",
       "      <td id=\"T_ee703_row6_col0\" class=\"data row6 col0\" >H</td>\n",
       "      <td id=\"T_ee703_row6_col1\" class=\"data row6 col1\" >H</td>\n",
       "      <td id=\"T_ee703_row6_col2\" class=\"data row6 col2\" >H</td>\n",
       "      <td id=\"T_ee703_row6_col3\" class=\"data row6 col3\" >H</td>\n",
       "      <td id=\"T_ee703_row6_col4\" class=\"data row6 col4\" >H</td>\n",
       "      <td id=\"T_ee703_row6_col5\" class=\"data row6 col5\" >H</td>\n",
       "      <td id=\"T_ee703_row6_col6\" class=\"data row6 col6\" >H</td>\n",
       "      <td id=\"T_ee703_row6_col7\" class=\"data row6 col7\" >H</td>\n",
       "      <td id=\"T_ee703_row6_col8\" class=\"data row6 col8\" >H</td>\n",
       "      <td id=\"T_ee703_row6_col9\" class=\"data row6 col9\" >H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ee703_level0_row7\" class=\"row_heading level0 row7\" >10</th>\n",
       "      <td id=\"T_ee703_row7_col0\" class=\"data row7 col0\" >H</td>\n",
       "      <td id=\"T_ee703_row7_col1\" class=\"data row7 col1\" >H</td>\n",
       "      <td id=\"T_ee703_row7_col2\" class=\"data row7 col2\" >H</td>\n",
       "      <td id=\"T_ee703_row7_col3\" class=\"data row7 col3\" >H</td>\n",
       "      <td id=\"T_ee703_row7_col4\" class=\"data row7 col4\" >H</td>\n",
       "      <td id=\"T_ee703_row7_col5\" class=\"data row7 col5\" >H</td>\n",
       "      <td id=\"T_ee703_row7_col6\" class=\"data row7 col6\" >H</td>\n",
       "      <td id=\"T_ee703_row7_col7\" class=\"data row7 col7\" >H</td>\n",
       "      <td id=\"T_ee703_row7_col8\" class=\"data row7 col8\" >H</td>\n",
       "      <td id=\"T_ee703_row7_col9\" class=\"data row7 col9\" >H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ee703_level0_row8\" class=\"row_heading level0 row8\" >9</th>\n",
       "      <td id=\"T_ee703_row8_col0\" class=\"data row8 col0\" >H</td>\n",
       "      <td id=\"T_ee703_row8_col1\" class=\"data row8 col1\" >H</td>\n",
       "      <td id=\"T_ee703_row8_col2\" class=\"data row8 col2\" >H</td>\n",
       "      <td id=\"T_ee703_row8_col3\" class=\"data row8 col3\" >H</td>\n",
       "      <td id=\"T_ee703_row8_col4\" class=\"data row8 col4\" >H</td>\n",
       "      <td id=\"T_ee703_row8_col5\" class=\"data row8 col5\" >H</td>\n",
       "      <td id=\"T_ee703_row8_col6\" class=\"data row8 col6\" >H</td>\n",
       "      <td id=\"T_ee703_row8_col7\" class=\"data row8 col7\" >H</td>\n",
       "      <td id=\"T_ee703_row8_col8\" class=\"data row8 col8\" >H</td>\n",
       "      <td id=\"T_ee703_row8_col9\" class=\"data row8 col9\" >H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ee703_level0_row9\" class=\"row_heading level0 row9\" >8</th>\n",
       "      <td id=\"T_ee703_row9_col0\" class=\"data row9 col0\" >H</td>\n",
       "      <td id=\"T_ee703_row9_col1\" class=\"data row9 col1\" >H</td>\n",
       "      <td id=\"T_ee703_row9_col2\" class=\"data row9 col2\" >H</td>\n",
       "      <td id=\"T_ee703_row9_col3\" class=\"data row9 col3\" >H</td>\n",
       "      <td id=\"T_ee703_row9_col4\" class=\"data row9 col4\" >H</td>\n",
       "      <td id=\"T_ee703_row9_col5\" class=\"data row9 col5\" >H</td>\n",
       "      <td id=\"T_ee703_row9_col6\" class=\"data row9 col6\" >H</td>\n",
       "      <td id=\"T_ee703_row9_col7\" class=\"data row9 col7\" >H</td>\n",
       "      <td id=\"T_ee703_row9_col8\" class=\"data row9 col8\" >H</td>\n",
       "      <td id=\"T_ee703_row9_col9\" class=\"data row9 col9\" >H</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1410b6c90>"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualize results\n",
    "df = pd.DataFrame.from_dict(results, orient='index')\n",
    "styled_df = df.style.map(color_strategy)\n",
    "styled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Wins: 41\n",
      "Total Games: 109\n",
      "Win Rate: 37.61%\n"
     ]
    }
   ],
   "source": [
    "# Report winrate\n",
    "\n",
    "import os\n",
    "def calculate_winrate(directory):\n",
    "    won = 0\n",
    "    total_games = 0\n",
    "\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".yaml\") or filename.endswith(\".yml\"):\n",
    "            filepath = os.path.join(directory, filename)\n",
    "\n",
    "            with open(filepath, \"r\") as file:\n",
    "                data = yaml.safe_load(file)\n",
    "\n",
    "                if \"final results\" in data[-1]:\n",
    "                    total_games += 1\n",
    "                    if str(data[-1][\"final results\"]).strip().lower() == \"win.\":\n",
    "                        won += 1\n",
    "\n",
    "    winrate = (won / total_games * 100) if total_games > 0 else 0\n",
    "    return won, total_games, winrate\n",
    "\n",
    "directory_path = \"../Agent-Pro/my_data/WSB\"\n",
    "wins, total, winrate = calculate_winrate(directory_path)\n",
    "\n",
    "print(f\"Total Wins: {wins}\")\n",
    "print(f\"Total Games: {total}\")\n",
    "print(f\"Win Rate: {winrate:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimal strategy\n",
    "\n",
    "<div>\n",
    "    <img src=\"../optimal_strategy.png\" width=\"500\"/>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
